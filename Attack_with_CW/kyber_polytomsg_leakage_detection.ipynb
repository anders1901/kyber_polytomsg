{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f628858",
   "metadata": {},
   "source": [
    "# Kyber $\\texttt{poly}\\_\\texttt{tomsg}$ Side Channel Analysis \n",
    "\n",
    "This Notebook contains:\n",
    "- ChipWhisperer setup for Kyber ref code\n",
    "- Leakage Detection on the $\\texttt{poly}\\_\\texttt{tomsg}$ function from `poly.c`\n",
    "- Side Channel Assisted Chosen Ciphertext Attack based on the previous leakage\n",
    "----- "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4baccb",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480b1c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading auxiliary functions for Chipwhisperer communication\n",
    "%run -i Chipwhisperer_functions.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6e8602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading auxiliary functions\n",
    "%run -i ../Common_functions/Additional_functions.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6bd24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing useful libraries\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import trange\n",
    "from scipy.stats import ttest_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f5b1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting default size of figures in Matplotlib\n",
    "plt.rcParams[\"figure.figsize\"] = (13, 3) \n",
    "\n",
    "# Set the maximum display width for NumPy arrays\n",
    "np.set_printoptions(linewidth=100)\n",
    "\n",
    "# Adjusting the display of tables\n",
    "np.set_printoptions(threshold=10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d65a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matplotlib constants \n",
    "span_color = \"#FFC069\"\n",
    "color1 = \"gold\"\n",
    "color0 = \"rebeccapurple\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b86aae",
   "metadata": {},
   "source": [
    "--------\n",
    "## Setup of the ChipWhisperer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad03dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base Scope for ChipWhisperer Lite \n",
    "SCOPETYPE = 'OPENADC'\n",
    "\n",
    "# ChipWhisperer Lite used Cortex-M4 \n",
    "PLATFORM = 'CWLITEARM'\n",
    "\n",
    "# Project Targeted\n",
    "CRYPTO_TARGET ='FKYBER'\n",
    "\n",
    "# SimpleSerial version used\n",
    "SS_VER = 'SS_VER_1_1'\n",
    "\n",
    "# Kyber K size, determines security level\n",
    "KYBER_K = repr(K)\n",
    "\n",
    "# If SHUFFLING = '0', the standard poly_tomsg is used; if SHUFFLING = '1', the shuffled poly_tomsg is used\n",
    "SHUFFLING = f\"{False:d}\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960cab1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detecting where is the ChipWhisperer setup notebook, if any\n",
    "probable_path_to_chipwhisperer_setup_notebook = !find ~/chipwhisperer/jupyter/Setup_Scripts/ -name \"Setup_Generic.ipynb\"\n",
    "\n",
    "print(f\"Probable path to ChipWhisperer jupyter setup script:\")\n",
    "print(f\">>> {probable_path_to_chipwhisperer_setup_notebook}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30512da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Change the path to match the location of your file Setup_Generic.ipynb\n",
    "# path_to_chipwhisperer_setup_notebook = ...\n",
    "path_to_chipwhisperer_setup_notebook = probable_path_to_chipwhisperer_setup_notebook[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86de0b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run $path_to_chipwhisperer_setup_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e11799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of samples that the ChipWhisperer has to record per trace\n",
    "scope.adc.samples = 24400"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36168ffd",
   "metadata": {},
   "source": [
    "### Compiling the Kyber code being analyzed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3f13e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detecting where is the simpleserial location, if any\n",
    "probable_path_to_simpleserial = !find ~ -name simpleserial-{CRYPTO_TARGET.lower()}\n",
    "\n",
    "print(f\"Probable path to communication protocol with the {CRYPTO_TARGET} code: \")\n",
    "print(f\">>> {probable_path_to_simpleserial}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae980963",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Change the path to match the location of the simpleserial code \n",
    "# path_to_simpleserial = ... \n",
    "path_to_simpleserial = probable_path_to_simpleserial[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6309ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%bash -s \"$path_to_simpleserial\" \"$PLATFORM\" \"$CRYPTO_TARGET\" \"$SS_VER\" \"$KYBER_K\" \"$SHUFFLING\"\n",
    "cd $1\n",
    "\n",
    "printf \"CLEANING PREVIOUS BUILD FILES:\\n\\n\"\n",
    "make -s clean PLATFORM=$2 CRYPTO_TARGET=$3 SS_VER=$4 \n",
    "rm -f ../crypto/fkyber/extra/*.o\n",
    "\n",
    "printf \"\\nBUILDING PROJECT FILES:\\n\\n\"\n",
    "make PLATFORM=$2 CRYPTO_TARGET=$3 SS_VER=$4 K=$5 SHUFFLED=$6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11bacc6",
   "metadata": {},
   "source": [
    "### Loading the executable into the ChipWhisperer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85dd5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detecting where is the simpleserial executable location, if any\n",
    "probable_path_to_executable = !find ~ -name simpleserial-{CRYPTO_TARGET.lower()}-{PLATFORM}.hex\n",
    "\n",
    "print(f\"Probable path to communication protocol with the {CRYPTO_TARGET} code: \")\n",
    "print(f\">>> {probable_path_to_executable}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b46397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Change the path to match the executable code \n",
    "# path_to_executable = ...\n",
    "path_to_executable = probable_path_to_executable[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67176c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cw.program_target(scope, prog, path_to_executable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43c3106",
   "metadata": {},
   "source": [
    "-----\n",
    "## Leakage Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d36be6a",
   "metadata": {},
   "source": [
    "### Sending the secret key to the ChipWhisperer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c016851b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read specified number of keys from the KAT file (from 1 to 100)\n",
    "number_keys_to_read = 1 \n",
    "keys_file_name = f'../Common_functions/PQCkemKAT_{KEM_SK_BYTES}.rsp'\n",
    "PK_KEM, SK_KEM = read_keys_from_KAT(number_keys_to_read, keys_file_name = keys_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f623a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Depending on the number of keys read (from 0 to number_keys_to_read - 1)\n",
    "index_sk_targeted = 0\n",
    " \n",
    "# Extracting the sk_KEM from the dictionnary of keys as an hex string\n",
    "hex_sk_KEM = SK_KEM[index_sk_targeted]\n",
    " \n",
    "# Extracting the sk_PKE from the sk_KEM as an hex string\n",
    "hex_sk_PKE = hex_sk_KEM[:2*SK_BYTES]\n",
    " \n",
    "# Converting the sk_PKE to polynomial vector representation\n",
    "polyvec_sk_PKE = hex_sk_to_int_sk(hex_sk_PKE)\n",
    "\n",
    "# Only for Chipwhisperer, serilizing the sk_PKE from the sk_KEM as chunks of hex string\n",
    "serialized_hex_sk_PKE = serialize_sk(hex_sk_PKE)\n",
    "\n",
    "print(\"sk trageted:\", polyvec_sk_PKE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2effeadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the secret key in the ChipWhisperer\n",
    "print(\"Sending sk:\", end = \" \")\n",
    "send_sk(serialized_hex_sk_PKE, reset = True)\n",
    "print(u\"\\u2705\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d222d144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just to check that communication succeeded \n",
    "hex_sk_PKE_output = get_full_sk_hex_str()\n",
    "\n",
    "if hex_sk_PKE_output.upper() == hex_sk_PKE:\n",
    "    print(\"sk correctly written to the Chipwhisperer\")\n",
    "else:\n",
    "    print(\"Problem with the sk written in the Chipwhisperer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042637ec-0412-44f5-be59-4030a937f22d",
   "metadata": {},
   "source": [
    "### Setting malicious $\\textbf{u}$ and $v$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16159932",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_coeffs_rounded0 = [-416%Q]\n",
    "print(f\"Reference malicious v for coeff rounded to 0: {int(math.remainder(v_coeffs_rounded0[0], Q))}\")\n",
    "\n",
    "# # If there is not enough leakage you can use this strategy\n",
    "# v_coeffs_rounded0 = [decompress(value, d = DV) for value in range(15, 12, -1)]\n",
    "# print(f\"Reference malicious v for coeff rounded to 0: {[int(math.remainder(v_coeffs_rounded0[i], Q)) for i in range(len(v_coeffs_rounded0))]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2289eeee",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_coeffs_rounded1 = [-1248%Q]\n",
    "print(f\"Reference malicious v for coeff rounded to 1: {int(math.remainder(v_coeffs_rounded1[0], Q))}\")\n",
    "\n",
    "# # If there is not enough leakage you can use this strategy\n",
    "# v_coeffs_rounded1 = [decompress(value, d = DV) for value in range(11, 8, -1)]\n",
    "# print(f\"Reference malicious v for coeff rounded to 0: {[int(math.remainder(v_coeffs_rounded1[i], Q)) for i in range(len(v_coeffs_rounded1))]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7a2b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_decompress_u_value = 42\n",
    "# # If there is not enough leakage you can use this strategy (only with alternative v strategy)\n",
    "# max_decompress_u_value = 21\n",
    "\n",
    "print(f\"Kyber{K*N} (minimal, maximal) secret value: ({-ETA1: 2d}, {ETA1: 2d})\")\n",
    "print(f\"Maximal malicious u: decompress({max_decompress_u_value}, d = {DU}) = {decompress(max_decompress_u_value, d= DU)}\")\n",
    "\n",
    "print(\"  For coeffs rounded to 0:\")\n",
    "print(f\"    {-(Q-1)//4} <= {int(math.remainder(v_coeffs_rounded0[0], Q))} - {ETA1} x {decompress(max_decompress_u_value, d= DU)} <= {0} \")\n",
    "print(f\"    {-(Q-1)//4} <= {int(math.remainder(v_coeffs_rounded0[0], Q))} + {ETA1} x {decompress(max_decompress_u_value, d= DU)} <= {0} \")\n",
    " \n",
    "print(\"  For coeffs rounded to 1:\")\n",
    "print(f\"    {-(Q-1)//2} <= {int(math.remainder(v_coeffs_rounded1[0], Q))} - {ETA1} x {decompress(max_decompress_u_value, d= DU)} < {-(Q-1)//4} \")\n",
    "print(f\"    {-(Q-1)//2} <= {int(math.remainder(v_coeffs_rounded1[0], Q))} + {ETA1} x {decompress(max_decompress_u_value, d= DU)} < {-(Q-1)//4} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39059d52-5cfe-4f6e-aa04-29b6dba3f11d",
   "metadata": {},
   "source": [
    "### Capturing traces during the decryption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b74583b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the reference means for coeff rounded to 0\n",
    "dataset_building_rounded0 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06318de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing u to zero\n",
    "polyvec_u = [[0 for _ in range(N)] for i in range(K)]\n",
    "\n",
    "for v_coeffs_rounded0_index in trange(0, len(v_coeffs_rounded0), desc = \"Capturing v\"):\n",
    "    # Setting malicious v\n",
    "    poly_v = [v_coeffs_rounded0[v_coeffs_rounded0_index]  for _ in range(N)]\n",
    "    \n",
    "    for u_value in trange(0, max_decompress_u_value, desc = \"Capturing u\"):\n",
    "        # Setting malicious u, only for first polynomial here \n",
    "        polyvec_u[0][0] = decompress(u_value, d = DU)\n",
    "\n",
    "        # Sending ciphertext to Chipwhisperer and performing decryption \n",
    "        ## If you want to check that communication succeeded, make sure read = True: \n",
    "        msg_bytes, trace = kyber_decrypt(polyvec_u, poly_v, read = False, capture = True)\n",
    "        \n",
    "        # Store complete trace for later use\n",
    "        dataset_building_rounded0.append(trace)\n",
    "        \n",
    "        ## If you want to check that communication succeeded, uncomment the following: \n",
    "        # hex_c_output = get_full_c_hex_str()\n",
    "        # polyvec_u_output, poly_v_output = hex_c_to_int_c1_c2(hex_c_output)\n",
    "        # assert polyvec_u_output == polyvec_u\n",
    "        # assert    poly_v_output ==    poly_v "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1c7d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the reference means for coeff rounded to 1\n",
    "dataset_building_rounded1 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67234232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing u to zero\n",
    "polyvec_u = [[0 for _ in range(N)] for i in range(K)]\n",
    "\n",
    "for v_coeffs_rounded1_index in trange(0, len(v_coeffs_rounded1), desc = \"Capturing v\"):\n",
    "    # Setting malicious v\n",
    "    poly_v = [v_coeffs_rounded1[v_coeffs_rounded1_index]  for _ in range(N)]\n",
    "    \n",
    "    for u_value in trange(0, max_decompress_u_value, desc = \"Capturing u\"):\n",
    "        # Setting malicious u \n",
    "        polyvec_u[0][0] = decompress(u_value, d = DU)\n",
    "\n",
    "        # Sending ciphertext to Chipwhisperer and performing decryption \n",
    "        ## If you want to check that communication succeeded, make sure read = True: \n",
    "        msg_bytes, trace = kyber_decrypt(polyvec_u, poly_v, read = False, capture = True)\n",
    "        \n",
    "        # Store complete trace for later use\n",
    "        dataset_building_rounded1.append(trace)\n",
    "        \n",
    "        ## If you want to check that communication succeeded, uncomment the following: \n",
    "        # hex_c_output = get_full_c_hex_str()\n",
    "        # polyvec_u_output, poly_v_output = hex_c_to_int_c1_c2(hex_c_output)\n",
    "        # assert polyvec_u_output == polyvec_u\n",
    "        # assert    poly_v_output ==    poly_v "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b502628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing 10 traces from each dataset\n",
    "plt.plot(np.transpose(dataset_building_rounded0[0:10]))\n",
    "plt.xlim(0,1400)\n",
    "plt.title(\"Traces from negative coefficient rounded to 0\",y=-0.4)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(np.transpose(dataset_building_rounded1[0:10]))\n",
    "plt.xlim(0,1400)\n",
    "plt.title(\"Traces from negative coefficient rounded to 1\",y=-0.4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b7bcee",
   "metadata": {},
   "source": [
    "### T-test between the two datasets \n",
    "\n",
    "As a first indicator, let's visualize the t-test between our two datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b400f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_value = ttest_ind(dataset_building_rounded0, dataset_building_rounded1, axis = 0, equal_var = False)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2ca3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fg, ax = plt.subplots(figsize = (13, 3))\n",
    "\n",
    "# Visualizing 10 traces from each dataset\n",
    "ax.plot(np.transpose(dataset_building_rounded1[:10]), color = color1, alpha=0.4)\n",
    "ax.plot(np.transpose(dataset_building_rounded0[:10]), color = color0, alpha=0.4)\n",
    "\n",
    "ax2 = ax.twinx()\n",
    "ax2.plot(t_value, color = \"tomato\", alpha = 1)\n",
    "ax.set_xlabel(\"samples\")\n",
    "ax.set_ylabel(\"power\")\n",
    "ax2.set_ylabel(\"t-value\")\n",
    "\n",
    "# Significance threshold\n",
    "plt.axhspan(-4.5, 4.5, color = \"C2\", alpha = 0.25)\n",
    "            \n",
    "plt.xlim(0, 1050)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ccf301",
   "metadata": {},
   "source": [
    "### Determining repeating patterns \n",
    "\n",
    "> ⚠️ This is a **quick** and **dirty** method only destined to be used for the sake of this attack  \n",
    "\n",
    "Here, we will try to automatically detect the patterns corresponding to the compressing of each coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc3a5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We retrieve the number of samples/cycles ratio of the CW (by default this should be 4)\n",
    "cw_sample_cycle_ratio =  int(scope.clock.adc_src[-1])\n",
    " \n",
    "# Making an educated guess on how many samples at the beginning of the trace correspond to the trigger\n",
    "cw_trigger_offset     = 6*cw_sample_cycle_ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771e020d",
   "metadata": {},
   "source": [
    "Let's analyze the C code from [github.com/pq-crystals/kyber/](https://github.com/pq-crystals/kyber/blob/main/ref/poly.c):\n",
    "\n",
    "```c\n",
    "void poly_tomsg(uint8_t msg[KYBER_INDCPA_MSGBYTES], const poly *a){\n",
    "  unsigned int i,j;\n",
    "  uint32_t t;\n",
    "  uint32_t  mask;\n",
    "  for(i=0;i<KYBER_N/8;i++) {\n",
    "    msg[i] = 0;\n",
    "    for(j=0;j<8;j++) {\n",
    "      t  = a->coeffs[8*i+j];\n",
    "      // t += ((int16_t)t >> 15) & KYBER_Q;\n",
    "      // t  = (((t << 1) + KYBER_Q/2)/KYBER_Q) & 1;\n",
    "      t <<= 1;\n",
    "      t += 1665;\n",
    "      t *= 80635;\n",
    "      t >>= 28;\n",
    "      t &= 1;\n",
    "      msg[i] |= t << j;   \n",
    "\n",
    "    }\n",
    "  }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91db48a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have 7 lines for the compression of one coefficient (code block inside the second `for` loop). \n",
    "nb_c_lines = 7\n",
    "\n",
    "# Let's guess that we will have at least cw_sample_cycle_ratio x 7 samples, for the operation we target \n",
    "min_samples_compress = cw_sample_cycle_ratio * nb_c_lines\n",
    "\n",
    "# As a maximum let's guess that this can result in 2 cycles per C line\n",
    "max_samples_compress = 2 * min_samples_compress"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a052560e",
   "metadata": {},
   "source": [
    "To start, we will focus on one full iteration of the second `for` loop  \n",
    "We can see that we will have 8 succesive compress somewhere in the beginning of the trace  \n",
    "So in the first samples of one trace we should have:\n",
    "* a few samples related to the chipwhisperer trigger process\n",
    "* some more few samples for the start of `for` loops\n",
    "* 8 patterns corresponding to the compress\n",
    "* some extra samples between the patterns for the logic behind the `for` loops.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f25ed20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The number of coefficient for the whole second for loop\n",
    "nb_coeffs                   = 8\n",
    "\n",
    "# An educated guess on how much samples are taken at the beginning of the poly_tomsg for loops\n",
    "start_function_offset       = 6 * cw_sample_cycle_ratio\n",
    "\n",
    "# Another educated guess on how much other operations are accounted for in the trace\n",
    "other_operations_samples    = 4 * cw_sample_cycle_ratio\n",
    "\n",
    "# Combining everything we have the approximate duration of the second for loop\n",
    "approximate_len_1for_j_loop =  cw_trigger_offset + start_function_offset\\\n",
    "                              + nb_coeffs * max_samples_compress\\\n",
    "                              + other_operations_samples "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d1cefa",
   "metadata": {},
   "source": [
    "Now that we have determined this smaller window, we can restrict our dataset to the part that we are analyzing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf45412",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.mean(dataset_building_rounded0, axis = 0)[:approximate_len_1for_j_loop]\n",
    "\n",
    "# Visualize the data with the identified operations \n",
    "plt.plot(data, color = color0)\n",
    "plt.axvspan(0, cw_trigger_offset, color = \"tan\", alpha = 0.2)\n",
    "y_pos = np.min(data) + 0.01\n",
    "\n",
    "plt.axvspan(cw_trigger_offset, cw_trigger_offset + start_function_offset, color = \"sandybrown\", alpha = 0.2)\n",
    "x_pos = (cw_trigger_offset + start_function_offset + cw_trigger_offset)/2\n",
    "plt.text(x_pos, y_pos, 'start\\nfor loop', horizontalalignment='center', verticalalignment='center', fontsize=9)\n",
    "\n",
    "plt.axvspan(cw_trigger_offset + start_function_offset, cw_trigger_offset + start_function_offset + nb_coeffs * max_samples_compress + other_operations_samples, color = \"green\", alpha = 0.2)\n",
    "x_pos = (cw_trigger_offset + start_function_offset + nb_coeffs * max_samples_compress + other_operations_samples + cw_trigger_offset)/2\n",
    "plt.text(x_pos, y_pos, f'poly_tomsg {nb_coeffs} first coefficients', horizontalalignment='center', verticalalignment='center', fontsize=9)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af3e7f1",
   "metadata": {},
   "source": [
    "After checking that everything looks good, we are ready to detect some patterns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170fbb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The minimal correlation tolerated between patterns\n",
    "limit = 0.99\n",
    "\n",
    "# The number of patterns tolerated with a correlation inferior to limit\n",
    "nb_not_good = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b40d04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "cpt_good_candidates = 0\n",
    "\n",
    "GOOD_CANDIDATES = []\n",
    "\n",
    "# Brute-forcing through all the starting points \n",
    "for start_point in range(cw_trigger_offset + start_function_offset, cw_trigger_offset + start_function_offset + cw_sample_cycle_ratio*4):\n",
    "    # Iterating through all the possible pattern lengths, starting from the largest\n",
    "    for length in range(max_samples_compress, min_samples_compress-1, -1):\n",
    "        # Maximum spacing between patterns so that we don't go outside the trace\n",
    "        max_spacing = (len(data) - start_point - nb_coeffs*length-1)//(nb_coeffs-1)\n",
    "        \n",
    "        # Iterating through all the possible spacing lengths, starting from the largest\n",
    "        for spacing in range(max_spacing, -1, -1):\n",
    "            potential_windows, window_start_index, window_end_index = [], [], []\n",
    "            \n",
    "            # Compute the first pattern, start point of window, end point of window and samples\n",
    "            new_window_start = start_point\n",
    "            window_start_index.append(new_window_start)\n",
    "\n",
    "            new_window_end   = new_window_start + length\n",
    "            window_end_index.append(new_window_end + 1)\n",
    "\n",
    "            potential_windows.append(data[new_window_start : new_window_end + 1])\n",
    "            \n",
    "            # Compute the other patterns based on the first one \n",
    "            for window_index in range(1, nb_coeffs):\n",
    "                new_window_start = new_window_end + spacing\n",
    "                window_start_index.append(new_window_start)\n",
    "\n",
    "                new_window_end   = new_window_start + length\n",
    "                window_end_index.append(new_window_end + 1)\n",
    "\n",
    "                potential_windows.append(data[new_window_start : new_window_end + 1])\n",
    "            \n",
    "            # Quality of matching patterns\n",
    "            measure = np.corrcoef(potential_windows)\n",
    "\n",
    "            if np.count_nonzero(measure <= limit) <= nb_not_good:\n",
    "                cpt_good_candidates += 1\n",
    "                GOOD_CANDIDATES.append([window_start_index, window_end_index, potential_windows])\n",
    "\n",
    "print(f\">>> You have found {len(GOOD_CANDIDATES)} good matching patterns candidates\", end = \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b5b250",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Visualizing all the good candidates previously found (can take a few seconds)\n",
    "for windows_index, element in enumerate(GOOD_CANDIDATES):\n",
    "    print(f\">>> Window #{windows_index}\")\n",
    "    window_start_index, window_end_index, potential_windows = element\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize = (13, 3))\n",
    "    ax.plot(data, color = color0, alpha = 1)\n",
    "    for window_index in range(0, len(potential_windows)):\n",
    "        plt.plot(range(window_start_index[window_index], window_end_index[window_index]), potential_windows[window_index], color = f\"C{window_index+1}\")\n",
    "        plt.axvspan(window_start_index[window_index], window_end_index[window_index], color = f\"C{window_index+1}\", alpha = 0.25)\n",
    "    ax.set_xlabel(\"samples\")\n",
    "    ax.set_ylabel(\"power\")\n",
    "    \n",
    "    ax2 = ax.twinx()\n",
    "    ax2.plot(t_value[:approximate_len_1for_j_loop],color=\"red\", alpha=1)\n",
    "    ax2.set_ylabel(\"t-value\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436a2411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select one candidate that looks good (by default the first one)\n",
    "index_chosen =  0\n",
    "\n",
    "# global compress_index_start, compress_index_end\n",
    "compress_index_start, compress_index_end, potential_windows = GOOD_CANDIDATES[index_chosen]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad7cee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based of this candidate set of patterns we can determine some constants \n",
    "# Start of the first poly_tomsg\n",
    "start_index_compress_coeff0 = compress_index_start[0]\n",
    "\n",
    "# Length of the first poly_tomsg\n",
    "approximate_length_compress_coeff = compress_index_end[0] - compress_index_start[0]\n",
    "\n",
    "# Distance between two for j loops\n",
    "distance_forj_loop_forj_loop = compress_index_start[1] - compress_index_end[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684537e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(data, color = color0)\n",
    "\n",
    "# Visualize the data with the identified operations \n",
    "plt.axvspan(0, cw_trigger_offset, color = \"tan\", alpha = 0.2)\n",
    "y_pos = np.min(data) + 0.01\n",
    "x_pos = (cw_trigger_offset + 0)/2\n",
    "plt.text(x_pos,y_pos, 'cw\\ntrigger', horizontalalignment='center', verticalalignment='center', fontsize=9)\n",
    "\n",
    "plt.axvspan(cw_trigger_offset, cw_trigger_offset + start_function_offset, color = \"sandybrown\", alpha = 0.2)\n",
    "x_pos = (cw_trigger_offset + start_function_offset + cw_trigger_offset)/2\n",
    "plt.text(x_pos, y_pos, 'start\\nfor loop', horizontalalignment='center', verticalalignment='center', fontsize=9)\n",
    "\n",
    "for compress_index in range(0, nb_coeffs):\n",
    "    start_window, end_window = compress_index_start[compress_index], compress_index_end[compress_index]\n",
    "    plt.axvspan(start_window, end_window, color = f\"C{compress_index+1}\", alpha = 0.25)\n",
    "    x_pos = (end_window + start_window)/2\n",
    "    plt.text(x_pos, y_pos, f'poly_tomsg\\ncoeff {compress_index}', horizontalalignment='center', verticalalignment='center', fontsize=9)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284fb442",
   "metadata": {},
   "source": [
    "The 8 patterns identified should hopefully correspond to the compression of the 8 first coefficients  \n",
    "\n",
    "We can use them to identify the rest  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e895ce92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One more educated guess on how much other operations are accounted for on the trace \n",
    "other_operations_samples    = 16 * cw_sample_cycle_ratio\n",
    "\n",
    "# Combining everything we have the approximate length of another iterationn of the second for loop\n",
    "approximate_len_2for_j_loop =  cw_trigger_offset + start_function_offset\\\n",
    "                             + 2*(compress_index_end[-1]- compress_index_start[0])\\\n",
    "                             + other_operations_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34941750",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.mean(dataset_building_rounded0, axis = 0)[:approximate_len_2for_j_loop]\n",
    "\n",
    "# Visualize the data with the identified operations \n",
    "plt.plot(data, color = color0)\n",
    "plt.axvspan(0, cw_trigger_offset, color = \"tan\", alpha = 0.2)\n",
    "y_pos = np.min(data) + 0.01\n",
    "x_pos = (cw_trigger_offset + 0)/2\n",
    "plt.text(x_pos,y_pos, 'cw\\ntrigger', horizontalalignment='center', verticalalignment='center', fontsize=7)\n",
    "\n",
    "plt.axvspan(cw_trigger_offset, cw_trigger_offset + start_function_offset, color = \"sandybrown\", alpha = 0.2)\n",
    "x_pos = (cw_trigger_offset + start_function_offset + cw_trigger_offset)/2\n",
    "plt.text(x_pos, y_pos, 'start\\nfor loop', horizontalalignment='center', verticalalignment='center', fontsize=7)\n",
    "\n",
    "plt.axvline(compress_index_start[0], color =\"red\")\n",
    "plt.axvline(compress_index_end[-1], color =\"red\")\n",
    "\n",
    "x_pos = (compress_index_end[-1]+compress_index_start[0])/2\n",
    "plt.text(x_pos, y_pos, f'poly_tomsg {nb_coeffs} first coefficients', horizontalalignment='center', fontsize=7)\n",
    "\n",
    "for compress_index in range(0, nb_coeffs):\n",
    "    start_window, end_window = compress_index_start[compress_index], compress_index_end[compress_index]\n",
    "    plt.axvspan(start_window, end_window, color = f\"C{compress_index+1}\", alpha = 0.25)\n",
    "\n",
    "plt.axvspan(compress_index_end[-1], approximate_len_2for_j_loop, color = \"green\", alpha = 0.2)\n",
    "x_pos = (compress_index_end[-1] + approximate_len_2for_j_loop)/2\n",
    "plt.text(x_pos, y_pos, f'poly_tomsg {nb_coeffs} next coefficients', horizontalalignment='center', verticalalignment='center', fontsize=9)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9e349a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Choose one coefficient as a reference to detect the next batch (default 0)\n",
    "coeffref = 0\n",
    "start_window, end_window = compress_index_start[coeffref], compress_index_end[coeffref]\n",
    "window_compress_coeffref = data[start_window : end_window]\n",
    "\n",
    "for start_point in range(compress_index_end[-1], approximate_len_2for_j_loop - approximate_length_compress_coeff):\n",
    "    potential_window_compress_coeff = data[start_point : start_point + approximate_length_compress_coeff]\n",
    "    measure = np.corrcoef(window_compress_coeffref, potential_window_compress_coeff)\n",
    "    if measure[0][1] >= limit:\n",
    "        potential_distance_fori_loop_forj_loop  = start_point - compress_index_end[-1]\n",
    "        print(f\"Good window found ({start_point}, {start_point + len(window_compress_coeffref)}) with quality {measure[0][1]}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2dd49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distance between the for i and for j loops\n",
    "distance_fori_loop_forj_loop = potential_distance_fori_loop_forj_loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd400cb",
   "metadata": {},
   "source": [
    "Automate the computation of window given the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7cc2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_compress_index_window(compress_index):\n",
    "    start_compress_index =  start_index_compress_coeff0\\\n",
    "                          + compress_index*approximate_length_compress_coeff\\\n",
    "                          + (compress_index//nb_coeffs)*(nb_coeffs-1)*distance_forj_loop_forj_loop\\\n",
    "                          + (compress_index%nb_coeffs)*distance_forj_loop_forj_loop\\\n",
    "                          + (compress_index//nb_coeffs)*distance_fori_loop_forj_loop\n",
    "    end_compress_index   = start_compress_index + approximate_length_compress_coeff\n",
    "    return start_compress_index, end_compress_index\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad439f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(data, color = color0)\n",
    "plt.axvspan(0, cw_trigger_offset, color = \"tan\", alpha = 0.2)\n",
    "y_pos = np.min(data) + 0.01\n",
    "x_pos = (cw_trigger_offset + 0)/2\n",
    "plt.text(x_pos,y_pos, 'cw\\ntrigger', horizontalalignment='center', verticalalignment='center', fontsize=7)\n",
    "\n",
    "plt.axvspan(cw_trigger_offset, cw_trigger_offset + start_function_offset, color = \"sandybrown\", alpha = 0.2)\n",
    "x_pos = (cw_trigger_offset + start_function_offset + cw_trigger_offset)/2\n",
    "plt.text(x_pos, y_pos, 'start\\nfor loop', horizontalalignment='center', verticalalignment='center', fontsize=7)\n",
    "\n",
    "plt.axvline(compress_index_start[0], color =\"red\")\n",
    "plt.axvline(compress_index_end[-1], color =\"red\")\n",
    "x_pos = (compress_index_end[-1]+compress_index_start[0])/2\n",
    "plt.text(x_pos, y_pos, f'poly_tomsg {nb_coeffs} first coefficients', horizontalalignment='center', fontsize=9)\n",
    "\n",
    "for compress_index in range(0, nb_coeffs):\n",
    "    start_window, end_window = get_compress_index_window(compress_index)\n",
    "    plt.axvspan(start_window, end_window, color = f\"C{compress_index+1}\", alpha = 0.25)\n",
    "\n",
    "for compress_index in range(nb_coeffs, 2*nb_coeffs):\n",
    "    start_window, end_window = get_compress_index_window(compress_index)\n",
    "    plt.axvspan(start_window, end_window, color = f\"C{compress_index%8+1}\", alpha = 0.25)\n",
    "\n",
    "x_pos = (get_compress_index_window(nb_coeffs)[0]  + get_compress_index_window(2*nb_coeffs-1)[0])/2\n",
    "plt.text(x_pos, y_pos, f'poly_tomsg {nb_coeffs} next coefficients', horizontalalignment='center', verticalalignment='center', fontsize=9)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f073e7b-632a-4c38-96a5-2ffbd0c8d86a",
   "metadata": {},
   "source": [
    "-----\n",
    "## Attack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec60b2d-be78-4b70-bee8-4476c3c7f3df",
   "metadata": {},
   "source": [
    "### Building reference means"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e459bcb-080d-4f1d-920a-fe8efdf00173",
   "metadata": {},
   "source": [
    "We will use leakage from the $N$ coefficients to build reference means for values for which:  \n",
    "- The value after applying $\\texttt{compress}$ is equal to $0$\n",
    "- The value after applying $\\texttt{compress}$ is equal to $1$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad70760-a5c1-4829-8b04-26e333e8caef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each trace in the dataset, we iterate through the N coeffs to get the window where each coeff is compressed\n",
    "# Then, we compute the mean trace for the negative coeff rounded to 0 after the compress on the first 256 coeffs\n",
    "traces_mean_rounded0 = []\n",
    "for trace in dataset_building_rounded0:\n",
    "    for compress_index in range(0, N):\n",
    "        start_window, end_window = get_compress_index_window(compress_index)\n",
    "        traces_mean_rounded0.append(trace[start_window: end_window + 1])\n",
    "        \n",
    "mean_rounded0 = np.mean(traces_mean_rounded0,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5348465-25ca-44e4-b92d-9975eefebea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each trace in the dataset, we iterate through the N coeffs to get the window where each coefficient is compressed\n",
    "# Then, we compute the mean trace for the negative coeff rounded to 1 on the compress on the first 256 coeffs\n",
    "traces_mean_rounded1 = []\n",
    "for trace in dataset_building_rounded1:\n",
    "    for compress_index in range(0, N):\n",
    "        start_window, end_window = get_compress_index_window(compress_index)\n",
    "        traces_mean_rounded1.append(trace[start_window: end_window + 1])\n",
    "        \n",
    "mean_rounded1 = np.mean(traces_mean_rounded1,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696c44cc-f972-4420-b1ec-0de67749cc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting to visualize the difference between mean_rouded0 and mean_rounded1\n",
    "plt.plot(mean_rounded0, color = color0, label='mean_rounded0')\n",
    "plt.plot(mean_rounded1, color = color1, label='mean_rounded1')\n",
    "\n",
    "plt.title(\"Means of each datasets\",y=-0.3)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cda7468-a8d6-46a6-bea0-57077d2853b2",
   "metadata": {},
   "source": [
    "After displaying all the 256 traces, we can see that only the samples between 9 and 10 exhibit strong leakage in our case. We will focus on those.\n",
    " \n",
    "⚠️  It’s possible that the leakage shifts depending on the pattern matching obtained. Adjust it to the window where you observe the most leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee8d62f-3e0b-43b9-9650-247ab452f580",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_start = 9\n",
    "reduced_len   = 2\n",
    "reduced_end   = reduced_start + reduced_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2193c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying the selected reduced window on all traces\n",
    "trace = dataset_building_rounded0[0]\n",
    "for compress_index in range(0, N):\n",
    "    start_window, end_window = get_compress_index_window(compress_index)\n",
    "    test = trace[start_window: end_window + 1]\n",
    "    if compress_index == 0:\n",
    "        plt.plot(test, color = color0, label = 'mean_rounded0')\n",
    "    else:\n",
    "        plt.plot(test, color = color0)\n",
    "    \n",
    "trace = dataset_building_rounded1[0]\n",
    "for compress_index in range(0, N):\n",
    "    start_window, end_window = get_compress_index_window(compress_index)\n",
    "    test = trace[start_window: end_window + 1]\n",
    "    if compress_index == 0:\n",
    "        plt.plot(test, color = color1, label = 'mean_rounded1')\n",
    "    else:\n",
    "        plt.plot(test, color = color1)\n",
    "\n",
    "plt.legend()\n",
    "plt.axvspan(reduced_start, reduced_end, color = \"green\", alpha = 0.2)\n",
    "plt.xlim(reduced_start-5, reduced_end+5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb1ffd4-d701-409b-a119-5975a8630fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_mean_rounded0 = mean_rounded0[reduced_start:reduced_end + 1]\n",
    "reduced_mean_rounded1 = mean_rounded1[reduced_start:reduced_end + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61337dc0-4589-4e52-b48a-50b2dbaff035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We redefine the function that computes the window on the restricted samples\n",
    "def get_compress_index_window(compress_index):\n",
    "    start_compress_index =  start_index_compress_coeff0\\\n",
    "                          + compress_index*approximate_length_compress_coeff\\\n",
    "                          + (compress_index//nb_coeffs)*(nb_coeffs-1)*distance_forj_loop_forj_loop\\\n",
    "                          + (compress_index%nb_coeffs)*distance_forj_loop_forj_loop\\\n",
    "                          + (compress_index//nb_coeffs)*distance_fori_loop_forj_loop\n",
    "    start_compress_index = start_compress_index + reduced_start\n",
    "    end_compress_index   = start_compress_index + reduced_len\n",
    "    return start_compress_index, end_compress_index\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0019e1",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Parallel Chosen Ciphertext Attack assisted with Side-channel "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dbea647",
   "metadata": {},
   "source": [
    "Refer to the paper for the choice of the malicious $\\mathbf{u}$ and $v$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54901dc-17d7-4736-904e-b284372ea6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "malicious_v_coeff = -(Q - 1)//4\n",
    "malicious_u_coeff =  (Q - 1)//16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6563dac1-07e5-4fb0-9a1f-613329fb3f21",
   "metadata": {},
   "source": [
    "We visualize the range of possible values for the secret coefficient based on the result of the compression given by the side-channel traces\n",
    "![test](graphe.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ede1ae5-5cbc-433d-8c18-8ecdd518ba81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_malicious_v(previous_v, previous_rounding, stage):\n",
    "    \"\"\"\n",
    "    Allows to get the corresponding malicious v based on the previous stage\n",
    "    malicious v and the previous rounding\n",
    "    \n",
    "    Inputs:\n",
    "    --------\n",
    "    previous_v        (int): previous stage malicious v\n",
    "    previous_rounding (int): previous rounding( 0 or 1)\n",
    "    stage             (int): stage of the attack\n",
    "    \n",
    "    Outputs:\n",
    "    --------\n",
    "      (int): corresponding malicious v for this stage \n",
    "    \"\"\"\n",
    "    return previous_v - pow(-1, previous_rounding)*(416//(stage))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31bea50-6649-4dac-a1b5-3ef7c5afea84",
   "metadata": {},
   "source": [
    "### Attack execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7054ebf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph transformed into dictionary\n",
    "secret_path_dict = {repr([0])      : [-3, -2, -1, 0],\n",
    "                    repr([1])      : [1, 2, 3],\n",
    "                    repr([0, 0])   : [-3, -2],\n",
    "                    repr([0, 1])   : [-1, 0],\n",
    "                    repr([1, 0])   : [1, 2],\n",
    "                    repr([1, 1])   : [3],\n",
    "                    repr([0, 0, 0]): [-3],\n",
    "                    repr([0, 0, 1]): [-2],\n",
    "                    repr([0, 1, 0]): [-1],\n",
    "                    repr([0, 1, 1]): [0],\n",
    "                    repr([1, 0, 0]): [1],\n",
    "                    repr([1, 0, 1]): [2],\n",
    "                    repr([1, 1, 0]): [3],\n",
    "                    repr([1, 1, 1]): [4]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9459efbd-2892-4ac8-8c45-dfa1de233d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the secret key, the actual value will be computed later\n",
    "found_polyvec_sk_PKE = [[None for coeff_ in range(N)] for poly_ in range(K)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304526df-f7fa-4edf-a3db-2ce7ed138057",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Keeps in memory the binary path for the secret key in the dictionnary \n",
    "MATCH = [[[] for coeff_ in range(N)] for poly_ in range(K)]\n",
    "ATK_TRACES = [[] for _ in range(K)]\n",
    "\n",
    "for poly_targeted in trange(K, desc = f\"Recovering poly of s\"):\n",
    "    polyvec_u = [[0 for coeff_ in range(N)] for poly_ in range(K)]\n",
    "    polyvec_u[poly_targeted][0] = malicious_u_coeff\n",
    "\n",
    "    for guess_stage in trange(3, desc = \"Sending queries to decrypt\"):    \n",
    "        if guess_stage == 0:\n",
    "            poly_v = [malicious_v_coeff for _ in range(256)]  \n",
    "        else:\n",
    "            for coeff_index in range(N):  \n",
    "                # poly_v[coeff_index] = poly_v[coeff_index] - pow(-1, MATCH[poly_targeted][coeff_index][-1])*(416//(guess_stage))  \n",
    "                poly_v[coeff_index] = get_malicious_v(poly_v[coeff_index], MATCH[poly_targeted][coeff_index][-1], guess_stage)\n",
    "        msg_bytes, trace = kyber_decrypt(polyvec_u, poly_v, capture = True)    \n",
    "        \n",
    "        ATK_TRACES[poly_targeted].append(trace)\n",
    "        \n",
    "        for coeff_index in range(N):\n",
    "            start_compress_coeff, end_compress_coeff = get_compress_index_window(coeff_index)\n",
    "            # Each trace is used to distinguish between coeffs rounded to 0 and coeffs rounded to 1\n",
    "            trace_compress_coeff = trace[start_compress_coeff:end_compress_coeff + 1]\n",
    "\n",
    "            # We choose the euclidian distance as a distinguisher to determine whether the trace chosen belongs to the \n",
    "            # set of traces rounded to 0 or the set of traces rounded to 1\n",
    "            norm_rounded0 = np.linalg.norm(reduced_mean_rounded0 - trace_compress_coeff)\n",
    "            norm_rounded1 = np.linalg.norm(reduced_mean_rounded1 - trace_compress_coeff)\n",
    "\n",
    "            MATCH[poly_targeted][coeff_index].append(np.argmin([norm_rounded0, norm_rounded1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79dc33f4-fa7d-4cf5-8122-8091897529a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Found secret key\n",
    "for poly_ in range(K):\n",
    "    for coeff_, match_path in enumerate(MATCH[poly_]):\n",
    "        found_polyvec_sk_PKE[poly_][coeff_] = secret_path_dict[repr(match_path)][0]\n",
    "print(\"The secret Key found is : \", found_polyvec_sk_PKE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7e4ac3-1eab-47a0-8bdc-e5ff86dac619",
   "metadata": {},
   "outputs": [],
   "source": [
    "if found_polyvec_sk_PKE == polyvec_sk_PKE :\n",
    "    print(f\"No errors, you have correctly guessed the secret key\")\n",
    "else :\n",
    "    print(f'You did not guess the secret key') \n",
    "    cpt_wron_coeffs = 0\n",
    "    \n",
    "    for poly_ in range(K):\n",
    "        for coeff_ in range(N):\n",
    "            if found_polyvec_sk_PKE[poly_][coeff_] != polyvec_sk_PKE[poly_][coeff_]:\n",
    "                cpt_wron_coeffs += 1\n",
    "    \n",
    "    print(f\"Number of wrongly guessed coefficients: {cpt_wron_coeffs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21765842-7c58-41f8-b4bc-c8d664453835",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # If you want to save the datasets used for the attack \n",
    "# np.savez(\"datasets_building\",\n",
    "#          dataset_building_rounded0=dataset_building_rounded0, \n",
    "#          dataset_building_rounded1=dataset_building_rounded1)\n",
    "\n",
    "# np.savez(f\"datasets_matching\",\n",
    "#          poly0_distinguisher_queries = ATK_TRACES[0], \n",
    "#          poly1_distinguisher_queries = ATK_TRACES[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef85a584-1383-40de-ab3f-8dbf4207ae72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # If the files were saved, we can load them to check if they are ok\n",
    "# name_of_file = \"datasets_building.npz\"\n",
    "# files = np.load(name_of_file)\n",
    "\n",
    "# name_files = files.files\n",
    "# print(f\"Files found in {name_of_file}:\")\n",
    "# for name_file in name_files:\n",
    "#     print(f\" - {name_file} containing {files[name_file].shape[0]} traces of {files[name_file].shape[1]} samples each\")\n",
    "\n",
    "# print(\"\")\n",
    "\n",
    "# name_of_file = \"datasets_matching.npz\"\n",
    "# files = np.load(name_of_file)\n",
    "\n",
    "# name_files = files.files\n",
    "# print(f\"Files found in {name_of_file}:\")\n",
    "# for name_file in name_files:\n",
    "#     print(f\" - {name_file} containing {files[name_file].shape[0]} traces of {files[name_file].shape[1]} samples each\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f73f48b-7e74-47af-aae5-09afc515a4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## \"\"\"Disconnect the ChipWhisperer if needed \"\"\" \n",
    "# disconnect_cw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be131fd-1535-4fcd-98ac-25046ea15f01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
